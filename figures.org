# -*- coding: utf-8 -*-
# -*- org-confirm-babel-evaluate: nil -*-
# -*- mode: org -*-
#+STARTUP: overview indent inlineimages logdrawer hidestars
* Context
** Top500
*** Downloading the data
The data has been compiled from the Top500 website by Dan Lenski (with a
contribution of Pedro Bruel). This data is used to generate the [[https://commons.wikimedia.org/wiki/File:Processor_families_in_TOP500_supercomputers.svg][Wikipedia]]
figure.

Note that the script is quite fragile. When I first tried it, it was broken, one
of the reasons was that the Top500 now requires a login/password to download the
data. I submitted [[https://github.com/dlenski/top500/issues/2][an issue]] on Github.

#+begin_src sh :results output :exports both
filename=data/context/TOP500_history.csv
wget https://github.com/dlenski/top500/raw/b6c4ddf1777447479757b5bda86ae7228227e331/TOP500_history.csv -O ${filename}
du -sh ${filename}
wc -l ${filename}
#+end_src

#+RESULTS:
: 8,8M	data/context/TOP500_history.csv
: 28001 data/context/TOP500_history.csv
*** Generating the figures
#+begin_src R :results output :session *R* :exports both
library(dplyr)
library(ggplot2)
library(patchwork)
df = read.csv("data/context/TOP500_history.csv")
str(df)
#+end_src

#+RESULTS:
#+begin_example

'data.frame':	28000 obs. of  53 variables:
 $ Year                           : int  1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 ...
 $ Month                          : int  6 6 6 6 6 6 6 6 6 6 ...
 $ Day                            : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Rank                           : num  1 2 3 4 5 6 7 8 9 10 ...
 $ Site                           : Factor w/ 2484 levels " Institute of Information and Communication Technologies at the Bulgarian Academy of Sciences",..: 1296 1390 1525 1498 1528 136 1519 281 473 568 ...
 $ Manufacturer                   : Factor w/ 148 levels "Acer Group","ACTION",..: 142 142 142 142 98 98 142 76 28 28 ...
 $ Computer                       : Factor w/ 2907 levels " eServer pSeries 655 (1.7 GHz Power4+)",..: 806 815 814 814 2413 2412 812 1017 2812 2812 ...
 $ Country                        : Factor w/ 63 levels "Australia","Austria",..: 61 61 61 61 27 7 61 61 61 61 ...
 $ Processors                     : num  1024 544 512 512 4 ...
 $ RMax                           : num  59.7 30.4 30.4 30.4 23.2 20 15.1 13.9 13.7 13.7 ...
 $ RPeak                          : num  131 69.6 65.5 65.5 25.6 ...
 $ Nmax                           : num  52224 36864 36864 36864 6400 ...
 $ Nhalf                          : num  24064 16384 16384 16384 830 ...
 $ Processor.Family               : Factor w/ 26 levels "","Alpha","AMD",..: 25 25 25 25 21 21 25 14 7 7 ...
 $ Processor                      : Factor w/ 484 levels "A64FX 48C 2.2GHz",..: 275 275 275 275 141 141 275 70 31 31 ...
 $ Processor.Speed..MHz.          : num  32 32 32 32 400 ...
 $ System.Family                  : Factor w/ 185 levels " IBM Power Systems",..: 180 180 180 180 124 124 180 106 34 34 ...
 $ Operating.System               : Factor w/ 93 levels "AIX","Amazon Linux 2",..: 12 12 12 12 65 65 12 34 81 81 ...
 $ Architecture                   : Factor w/ 6 levels "Cluster","Constellations",..: 3 3 3 3 6 6 3 3 6 6 ...
 $ Segment                        : Factor w/ 7 levels "Academic","Classified",..: 6 4 1 2 7 6 6 1 7 6 ...
 $ Application.Area               : Factor w/ 48 levels "","Aerospace",..: 37 37 37 37 37 46 37 37 37 37 ...
 $ Interconnect.Family            : Factor w/ 27 levels "10G","Cray Interconnect",..: 8 8 8 8 3 3 8 17 17 17 ...
 $ Interconnect                   : Factor w/ 100 levels "100G Ethernet",..: 39 39 39 39 75 75 39 79 79 79 ...
 $ Region                         : Factor w/ 17 levels "","Australia and New Zealand",..: 7 7 7 7 5 7 7 7 7 7 ...
 $ Continent                      : Factor w/ 7 levels "Africa","Americas",..: 2 2 2 2 3 2 2 2 2 2 ...
 $ Power                          : num  NA NA NA NA NA NA NA NA NA NA ...
 $ System.Model                   : Factor w/ 564 levels "","Acer AR585 F1 Cluster",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Total.Cores                    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Measured.Size                  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Processor.Cores                : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Accelerator                    : Factor w/ 7 levels "","ATI GPU","IBM PowerXCell 8i",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Name                           : Factor w/ 898 levels "","1","2","A1",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Accelerator.Cores              : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Efficiency....                 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Mflops.Watt                    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Processor.Technology           : Factor w/ 28 levels "","AMD x86_64",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ OS.Family                      : Factor w/ 39 levels "","Amazon Linux 2",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Cores.per.Socket               : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Processor.Generation           : Factor w/ 76 levels "","AMD Naples",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Previous.Rank                  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ First.Appearance               : num  NA NA NA NA NA NA NA NA NA NA ...
 $ First.Rank                     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Accelerator.Co.Processor.Cores : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Accelerator.Co.Processor       : Factor w/ 64 levels "","AMD FirePro S10000",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Power.Source                   : Factor w/ 4 levels "","Derived","Optimized",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Rmax..TFlop.s.                 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Rpeak..TFlop.s.                : num  NA NA NA NA NA NA NA NA NA NA ...
 $ HPCG..TFlop.s.                 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Power..kW.                     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Power.Effeciency..GFlops.Watts.: num  NA NA NA NA NA NA NA NA NA NA ...
 $ Site.ID                        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ System.ID                      : int  NA NA NA NA NA NA NA NA NA NA ...
 $ Power.Efficiency..GFlops.Watts.: num  NA NA NA NA NA NA NA NA NA NA ...
#+end_example

There are several columns to denote a number of cores (total, only cpu, only
accelerators...).
#+begin_src R :results output :session *R* :exports both
df %>% filter(Year == 2020, Month==11, Rank %in% c(2,3,5)) %>% select(Site, Processor, Accelerator.Co.Processor, Total.Cores, Processor.Cores, Accelerator.Co.Processor.Cores, Accelerator.Cores)
#+end_src

#+RESULTS:
#+begin_example
                                  Site                 Processor
1 DOE/SC/Oak Ridge National Laboratory    IBM POWER9 22C 3.07GHz
2                        DOE/NNSA/LLNL     IBM POWER9 22C 3.1GHz
3                   NVIDIA Corporation AMD EPYC 7742 64C 2.25GHz
  Accelerator.Co.Processor Total.Cores Processor.Cores
1       NVIDIA Volta GV100     2414592              NA
2       NVIDIA Volta GV100     1572480              NA
3              NVIDIA A100      555520              NA
  Accelerator.Co.Processor.Cores Accelerator.Cores
1                        2211840                NA
2                        1382400                NA
3                         483840                NA
#+end_example

So, let's unify and clean the data.
#+begin_src R :results output :session *R* :exports both
df = df %>%
    mutate(date=ISOdate(Year, Month, Day)) %>%
    mutate(perf_hpl=ifelse(is.na(RMax), Rmax..TFlop.s.*1000, RMax)) %>%
    mutate(perf_theoretical=ifelse(is.na(RPeak), Rpeak..TFlop.s.*1000, RMax)) %>%
    mutate(perf_hpcg=HPCG..TFlop.s.*1000) %>%
    mutate(efficiency=perf_hpl/perf_theoretical) %>%
    mutate(total_cores=ifelse(is.na(Total.Cores), Processors, Total.Cores)) %>%
    mutate(accelerator_cores=ifelse(is.na(Accelerator.Cores), 0, Accelerator.Cores)) %>%
    mutate(accelerator_cores=ifelse(is.na(Accelerator.Co.Processor.Cores), accelerator_cores, Accelerator.Co.Processor.Cores)) %>%
    mutate(cpu_cores=total_cores-accelerator_cores) %>%
    mutate(proc_freq=Processor.Speed..MHz.)
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
df %>% filter(Year == 2020, Month==11, Rank <= 10) %>% select(Site, total_cores, cpu_cores, accelerator_cores)
#+end_src

#+RESULTS:
#+begin_example
                                             Site total_cores cpu_cores
1          RIKEN Center for Computational Science     7630848   7630848
2            DOE/SC/Oak Ridge National Laboratory     2414592    202752
3                                   DOE/NNSA/LLNL     1572480    190080
4          National Supercomputing Center in Wuxi    10649600  10649600
5                              NVIDIA Corporation      555520     71680
6     National Super Computer Center in Guangzhou     4981760    427008
7                 Forschungszentrum Juelich (FZJ)      449280     44928
8                                      Eni S.p.A.      669760     87360
9  Texas Advanced Computing Center/Univ. of Texas      448448    448448
10                                   Saudi Aramco      672520     39560
   accelerator_cores
1                  0
2            2211840
3            1382400
4                  0
5             483840
6            4554752
7             404352
8             582400
9                  0
10            632960
#+end_example

#+begin_src R :results output :session *R* :exports both
group_top500 = function(df, y_col, group_col, q) {
    return (df %>%
        group_by(.data[[group_col]]) %>%
        filter(!any(is.na(.data[[y_col]]))) %>%
        summarise(min_val=min(.data[[y_col]]),
                  small_val=quantile(.data[[y_col]], q),
                  med_val=median(.data[[y_col]]),
                  large_val=quantile(.data[[y_col]], 1-q),
                  max_val=max(.data[[y_col]])
        )
    )
}
plot_top500 = function(df, y_col, x_col, color) {
    q = 0.1
    df %>% group_top500(y_col, x_col, q) %>%
        ggplot() +
        aes_string(x=x_col, ymin="min_val", ymax="max_val", y="med_val") +
        geom_line(color=color) +
        geom_ribbon(alpha=0.3, fill=color) +
        geom_ribbon(aes_string(ymin="small_val", ymax="large_val"), alpha=0.3, fill=color) +
        theme_light() -> plot
    return(plot)
}
#+end_src

#+RESULTS:

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
p_cores = plot_top500(df, "total_cores",  "date", "#1b9e77") +
    scale_y_log10(breaks=c(1e1, 1e3, 1e5, 1e7)) +
    ggtitle("Number of cores")
p_freq  = plot_top500(df, "proc_freq", "date", "#d95f02") +
    scale_y_log10(breaks=c(8, 40, 200, 1000, 5000)) +
    ggtitle("CPU frequency (MHz)")
p_perf  = plot_top500(df, "perf_hpl",  "date", "#7570b3") +
    scale_y_log10(breaks=c(1e0, 1e2, 1e4, 1e6, 1e8)) +
    ggtitle("Performance (Gflop/s)")
min_year = df %>% pull(Year) %>% min()
max_year = df %>% pull(Year) %>% max()
plot = (p_cores + p_freq + p_perf & 
    theme(axis.title.x=element_blank(),
          axis.title.y=element_blank()
        )
    ) +
    plot_annotation(title=paste("Top500 evolution from", min_year, "to", max_year),
#                   subtitle="Showing the quantiles [0, 0.1, 0.5, 0.9, 1]",
                    caption="Data from https://top500.org, compiled by Dan Lenski and plotted by Tom Cornebize")
ggsave(filename='img/context/top500.pdf', plot=plot, width=7, height=3)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-Y7Z50c/figureATURtA.png]]


#+begin_src R :results output :session *R* :exports both
df %>%
    filter(proc_freq >= 3500) %>%
    select(Processor, proc_freq) %>%
    unique() %>%
    arrange(-proc_freq)
#+end_src

#+RESULTS:
#+begin_example

                        Processor proc_freq
1                          POWER6      5000
2                          POWER6      4700
3               POWER6 2C 4.70GHz      4700
4              POWER6 2C 4.700GHz      4700
5                   PowerXCell 8i      4000
6                          POWER7      3860
7               POWER7 8C 3.86GHz      3860
8                          POWER7      3836
9              POWER7 8C 3.836GHz      3836
10              POWER7 8C 3.84GHz      3836
11              POWER7 8C 3.83GHz      3830
12         Intel EM64T Xeon EM64T      3600
13     Intel IA-32 Pentium 4 Xeon      3600
14            Xeon EM64T  3.60GHz      3600
15       Xeon E3-1280v3 4C 3.6GHz      3600
16       Xeon Gold 5122 4C 3.6GHz      3600
17          IBM POWER9 20C 3.6GHz      3600
18             POWER7  8C 3.55GHz      3550
19 Intel Xeon E5-2637v2 4C 3.5GHz      3500
#+end_example

* Performance prediction through simulation
** Modeling HPL kernels and communications
*** Kernels plots                                                :noexport:
**** Downloading the CSV
The file trace_functions.csv has been generated with this [[https://github.com/Ezibenroc/mpi_calibration/blob/74870b0d26497cf623c47a747e2f089eedb62857/dahu/hpl/hpl_trace_simple.ipynb][notebook]] (the dump to
the CSV file happens in cells 25-26). The notebook uses this [[https://github.com/Ezibenroc/mpi_calibration/blob/74870b0d26497cf623c47a747e2f089eedb62857/dahu/smpi_hpl/grenoble_2019-04-03_1858209.zip][ZIP archive]].

The file dgemm_calibration.csv has been generated with this [[https://github.com/Ezibenroc/mpi_calibration/blob/df5a957901fac35a3df0bd466acea7d6199a9426/dahu/blas/dgemm_heterogeneous_model.ipynb][notebook]] (the dump
to the CSV file happens in cell 38). The notebook uses these [[https://github.com/Ezibenroc/mpi_calibration/tree/26fdfbb565e1eb5b9f1015a47ddd8fe9aaa424e5/dahu/blas/heterogeneity_exp/7][ZIP archives]].

#+begin_src sh :results output :exports both
mkdir -p data/prediction/modeling/kernels/
cd data/prediction/modeling/kernels/
wget -c https://github.com/Ezibenroc/mpi_calibration/raw/master/dahu/smpi_hpl/paper_sc19/traces/2/trace_functions.csv
sed 's/function/func/g' -i trace_functions.csv  # cannot have a column named "function" in R...
wget -c https://github.com/Ezibenroc/mpi_calibration/raw/master/dahu/blas/dgemm_calibration.csv
sed 's/function/func/g' -i dgemm_calibration.csv  # cannot have a column named "function" in R...
#+end_src

#+RESULTS:

**** Drawing the regression plots
There are several interesting functions in the CSV file. For each function,
there are real observations *and* predictions, the column "mode" can be used to
distinguish them.

***** DGEMM from a calibration
#+begin_src R :results output :session *R* :exports both
library(ggplot2)
options(crayon.enabled = FALSE)
df = read.csv('data/prediction/modeling/kernels/dgemm_calibration.csv')
str(df)
#+end_src

#+RESULTS:
#+begin_example

'data.frame':	5004288 obs. of  14 variables:
 $ func        : Factor w/ 1 level "dgemm": 1 1 1 1 1 1 1 1 1 1 ...
 $ m           : int  378 378 378 9441 9441 9441 1041 1041 1041 1248 ...
 $ n           : int  7640 7640 7640 640 640 640 2183 2183 2183 1343 ...
 $ k           : int  2427 2427 2427 1160 1160 1160 735 735 735 1991 ...
 $ timestamp   : num  3473 3474 3474 3475 3475 ...
 $ duration    : num  0.486 0.486 0.487 0.455 0.454 ...
 $ prediction  : num  0.522 0.522 0.522 0.485 0.485 ...
 $ noise       : num  0.000512 -0.004775 0.001385 -0.001869 0.004448 ...
 $ pred_noise  : num  0.522 0.517 0.523 0.483 0.489 ...
 $ node        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ core        : int  0 0 0 0 0 0 0 0 0 0 ...
 $ cpu         : int  20 20 20 20 20 20 20 20 20 20 ...
 $ index       : int  0 1 2 3 4 5 6 7 8 9 ...
 $ index_in_seq: int  0 1 2 0 1 2 0 1 2 0 ...
#+end_example

#+begin_src R :results output :session *R* :exports both
## df$node = 1 + df$rank %/% 32
## df$cpu = 2*df$node + df$rank %% 2
df$m = as.numeric(df$m)
df$n = as.numeric(df$n)
df$k = as.numeric(df$k)
## df$mnk = df$m * df$n * df$k
## df$mn = df$m * df$n
## df$mk = df$m * df$k
## df$nk = df$n * df$k
str(df)
head(df)
#+end_src

#+RESULTS:
#+begin_example

'data.frame':	5004288 obs. of  14 variables:
 $ func        : Factor w/ 1 level "dgemm": 1 1 1 1 1 1 1 1 1 1 ...
 $ m           : num  378 378 378 9441 9441 ...
 $ n           : num  7640 7640 7640 640 640 ...
 $ k           : num  2427 2427 2427 1160 1160 ...
 $ timestamp   : num  3473 3474 3474 3475 3475 ...
 $ duration    : num  0.486 0.486 0.487 0.455 0.454 ...
 $ prediction  : num  0.522 0.522 0.522 0.485 0.485 ...
 $ noise       : num  0.000512 -0.004775 0.001385 -0.001869 0.004448 ...
 $ pred_noise  : num  0.522 0.517 0.523 0.483 0.489 ...
 $ node        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ core        : int  0 0 0 0 0 0 0 0 0 0 ...
 $ cpu         : int  20 20 20 20 20 20 20 20 20 20 ...
 $ index       : int  0 1 2 3 4 5 6 7 8 9 ...
 $ index_in_seq: int  0 1 2 0 1 2 0 1 2 0 ...

   func    m    n    k timestamp  duration prediction         noise pred_noise
1 dgemm  378 7640 2427  3473.428 0.4859466  0.5217815  0.0005118576  0.5222933
2 dgemm  378 7640 2427  3473.914 0.4861293  0.5217815 -0.0047750420  0.5170064
3 dgemm  378 7640 2427  3474.401 0.4868529  0.5217815  0.0013853568  0.5231668
4 dgemm 9441  640 1160  3474.887 0.4551385  0.4845474 -0.0018686303  0.4826788
5 dgemm 9441  640 1160  3475.343 0.4535278  0.4845474  0.0044477582  0.4889952
6 dgemm 9441  640 1160  3475.796 0.4544535  0.4845474  0.0007154680  0.4852629
  node core cpu index index_in_seq
1   10    0  20     0            0
2   10    0  20     1            1
3   10    0  20     2            2
4   10    0  20     3            0
5   10    0  20     4            1
6   10    0  20     5            2
#+end_example

#+begin_src R :results output :session *R* :exports both
unique(df$node)
unique(df$cpu)
#+end_src

#+RESULTS:
:  [1] 10 26 31  3 13 18  6  7 29  8  2 20 16  9 23 15 32 22 14 19 12 25 30 17 24
: [26] 11  1  5  4 28 21 27
: 
:  [1] 20 21 52 53 62 63  6  7 26 27 36 37 12 13 14 15 58 59 16 17  4  5 40 41 32
: [26] 33 18 19 46 47 30 31 64 65 44 45 28 29 38 39 24 25 50 51 60 61 34 35 48 49
: [51] 22 23  2  3 10 11  8  9 56 57 42 43 54 55

#+begin_src R :results output :session *R* :exports both
set.seed(42)
dgemm = df[sample(nrow(df), 100000), ] # This is too large to be plotted
dgemm = dgemm[dgemm$m*dgemm$n*dgemm$k<1.2E10,]
summary(lm(data=dgemm, duration ~ I(m*n*k):factor(cpu)))
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = duration ~ I(m * n * k):factor(cpu), data = dgemm)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.11522 -0.01048 -0.00429  0.00465  0.40312 

Coefficients:
                            Estimate Std. Error t value Pr(>|t|)    
(Intercept)                7.286e-03  1.895e-04   38.45   <2e-16 ***
I(m * n * k):factor(cpu)2  6.791e-11  1.309e-13  518.72   <2e-16 ***
I(m * n * k):factor(cpu)3  6.598e-11  1.255e-13  525.83   <2e-16 ***
I(m * n * k):factor(cpu)4  6.678e-11  1.285e-13  519.57   <2e-16 ***
I(m * n * k):factor(cpu)5  6.562e-11  1.285e-13  510.70   <2e-16 ***
I(m * n * k):factor(cpu)6  6.639e-11  1.297e-13  511.93   <2e-16 ***
I(m * n * k):factor(cpu)7  6.564e-11  1.290e-13  508.83   <2e-16 ***
I(m * n * k):factor(cpu)8  6.571e-11  1.257e-13  522.58   <2e-16 ***
I(m * n * k):factor(cpu)9  6.578e-11  1.315e-13  500.38   <2e-16 ***
I(m * n * k):factor(cpu)10 6.640e-11  1.296e-13  512.53   <2e-16 ***
I(m * n * k):factor(cpu)11 6.498e-11  1.314e-13  494.67   <2e-16 ***
I(m * n * k):factor(cpu)12 6.800e-11  1.293e-13  525.83   <2e-16 ***
I(m * n * k):factor(cpu)13 6.524e-11  1.305e-13  499.99   <2e-16 ***
I(m * n * k):factor(cpu)14 6.575e-11  1.319e-13  498.29   <2e-16 ***
I(m * n * k):factor(cpu)15 6.493e-11  1.288e-13  504.21   <2e-16 ***
I(m * n * k):factor(cpu)16 6.704e-11  1.304e-13  513.99   <2e-16 ***
I(m * n * k):factor(cpu)17 6.549e-11  1.335e-13  490.44   <2e-16 ***
I(m * n * k):factor(cpu)18 6.561e-11  1.289e-13  509.12   <2e-16 ***
I(m * n * k):factor(cpu)19 6.562e-11  1.316e-13  498.71   <2e-16 ***
I(m * n * k):factor(cpu)20 6.563e-11  1.287e-13  509.88   <2e-16 ***
I(m * n * k):factor(cpu)21 6.552e-11  1.279e-13  512.35   <2e-16 ***
I(m * n * k):factor(cpu)22 6.553e-11  1.292e-13  507.31   <2e-16 ***
I(m * n * k):factor(cpu)23 6.616e-11  1.301e-13  508.46   <2e-16 ***
I(m * n * k):factor(cpu)24 6.574e-11  1.326e-13  495.87   <2e-16 ***
I(m * n * k):factor(cpu)25 6.524e-11  1.317e-13  495.54   <2e-16 ***
I(m * n * k):factor(cpu)26 8.713e-11  1.268e-13  687.18   <2e-16 ***
I(m * n * k):factor(cpu)27 7.167e-11  1.276e-13  561.80   <2e-16 ***
I(m * n * k):factor(cpu)28 7.355e-11  1.237e-13  594.39   <2e-16 ***
I(m * n * k):factor(cpu)29 7.314e-11  1.307e-13  559.58   <2e-16 ***
I(m * n * k):factor(cpu)30 8.033e-11  1.277e-13  628.82   <2e-16 ***
I(m * n * k):factor(cpu)31 7.971e-11  1.248e-13  638.52   <2e-16 ***
I(m * n * k):factor(cpu)32 7.550e-11  1.243e-13  607.29   <2e-16 ***
I(m * n * k):factor(cpu)33 7.458e-11  1.242e-13  600.67   <2e-16 ***
I(m * n * k):factor(cpu)34 7.008e-11  1.287e-13  544.54   <2e-16 ***
I(m * n * k):factor(cpu)35 6.590e-11  1.299e-13  507.49   <2e-16 ***
I(m * n * k):factor(cpu)36 6.932e-11  1.261e-13  549.80   <2e-16 ***
I(m * n * k):factor(cpu)37 6.562e-11  1.302e-13  503.95   <2e-16 ***
I(m * n * k):factor(cpu)38 6.577e-11  1.314e-13  500.63   <2e-16 ***
I(m * n * k):factor(cpu)39 6.561e-11  1.299e-13  505.01   <2e-16 ***
I(m * n * k):factor(cpu)40 6.609e-11  1.265e-13  522.63   <2e-16 ***
I(m * n * k):factor(cpu)41 6.571e-11  1.315e-13  499.61   <2e-16 ***
I(m * n * k):factor(cpu)42 6.594e-11  1.264e-13  521.55   <2e-16 ***
I(m * n * k):factor(cpu)43 6.556e-11  1.302e-13  503.67   <2e-16 ***
I(m * n * k):factor(cpu)44 6.540e-11  1.271e-13  514.54   <2e-16 ***
I(m * n * k):factor(cpu)45 6.583e-11  1.269e-13  518.93   <2e-16 ***
I(m * n * k):factor(cpu)46 6.576e-11  1.264e-13  520.27   <2e-16 ***
I(m * n * k):factor(cpu)47 6.485e-11  1.299e-13  499.12   <2e-16 ***
I(m * n * k):factor(cpu)48 6.571e-11  1.277e-13  514.57   <2e-16 ***
I(m * n * k):factor(cpu)49 6.536e-11  1.287e-13  507.92   <2e-16 ***
I(m * n * k):factor(cpu)50 6.991e-11  1.316e-13  531.20   <2e-16 ***
I(m * n * k):factor(cpu)51 6.498e-11  1.287e-13  504.95   <2e-16 ***
I(m * n * k):factor(cpu)52 6.571e-11  1.295e-13  507.31   <2e-16 ***
I(m * n * k):factor(cpu)53 6.618e-11  1.290e-13  512.99   <2e-16 ***
I(m * n * k):factor(cpu)54 6.580e-11  1.264e-13  520.51   <2e-16 ***
I(m * n * k):factor(cpu)55 6.613e-11  1.288e-13  513.36   <2e-16 ***
I(m * n * k):factor(cpu)56 6.727e-11  1.291e-13  521.17   <2e-16 ***
I(m * n * k):factor(cpu)57 6.565e-11  1.274e-13  515.47   <2e-16 ***
I(m * n * k):factor(cpu)58 6.585e-11  1.287e-13  511.46   <2e-16 ***
I(m * n * k):factor(cpu)59 6.561e-11  1.270e-13  516.45   <2e-16 ***
I(m * n * k):factor(cpu)60 6.611e-11  1.292e-13  511.65   <2e-16 ***
I(m * n * k):factor(cpu)61 6.549e-11  1.282e-13  510.93   <2e-16 ***
I(m * n * k):factor(cpu)62 6.552e-11  1.288e-13  508.73   <2e-16 ***
I(m * n * k):factor(cpu)63 6.565e-11  1.315e-13  499.12   <2e-16 ***
I(m * n * k):factor(cpu)64 6.543e-11  1.297e-13  504.30   <2e-16 ***
I(m * n * k):factor(cpu)65 6.557e-11  1.267e-13  517.44   <2e-16 ***
---
codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.02932 on 99772 degrees of freedom
Multiple R-squared:  0.9783,	Adjusted R-squared:  0.9783 
F-statistic: 7.027e+04 on 64 and 99772 DF,  p-value: < 2.2e-16
#+end_example

Regression lines, to show the heterogeneity.
#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 400 :height 400 :session *R* 
plot = ggplot(dgemm, aes(x=m*n*k, y=duration, color=factor(cpu%%9))) +
    geom_point(alpha=.1,size=.5) + 
    geom_smooth(data=dgemm, aes(group=factor(cpu)), method='lm', se=F, fullrange=T, size=.5) +
    geom_smooth(data=dgemm, color="black", method='lm', se=F, fullrange=T, linetype=4) +
    scale_color_brewer(palette="Set1", guide=F)
plot = plot + theme_bw() + ylab('Duration (s)') + 
    scale_x_continuous(name = 'M.N.K', breaks = (0:4)*3E9, limits=c(0,1.2E10)) + 
    labs(color='CPU') 
ggsave(filename='img/prediction/modeling/kernels/dgemm_heterogeneity_calib.png', plot=plot, width=3.9,height=3, dpi=200)
## ggsave(filename="figures/kernels/dgemm_heterogeneity.pdf", plot=plot, width=4,height=4)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-Kejzdq/figurebgL9vP.png]]


#+begin_src R :results output :session *R* :exports both
library(dplyr)
library(tidyr)
library(forcats)

dgemm2 = dgemm[(dgemm$cpu ==2),]
dgemm2 %>% select(func,m,n,k,duration,prediction,pred_noise,node,core,cpu) %>%
    gather(duration,prediction,pred_noise,key=type,value=duration) -> dgemm2
fake_dgemm = dgemm2[1,] # This is just to add a black legend for geom_smooth
fake_dgemm$m = 695 # 0 if even values of mnk_id are selected
fake_dgemm$n = 695 # 0
fake_dgemm$k = 695 # 0 
fake_dgemm$type = "fake"
fake_dgemm$duration = 0
dgemm2 = rbind(fake_dgemm, dgemm2)
dgemm2 %>%
    mutate(type = fct_recode(
               fct_relevel(type, "duration", "fake", "prediction", "pred_noise"),
               "Reality"="duration", 
               "M1/N0 (linear)"="fake", 
               "M2/N0 (polynomial)"="prediction",
               "M2/N2 (polynomial + noise)"="pred_noise")) -> dgemm2
dgemm2 %>% mutate(mnk=m*n*k, mnk_id = floor(mnk/329334390)) %>% filter(mnk_id %%2==1) -> dgemm2
dgemm2 %>% 
    group_by(type) %>% 
    mutate(mnk= mnk + ifelse(type=="M2/N0 (polynomial)",1.5E8,ifelse(type=="M2/N2 (polynomial + noise)",3E8,0)),
           duration = ifelse(type %in% c("M2/N0 (polynomial)","M2/N2 (polynomial + noise)"),duration/1.05,duration)) %>% # This is because this prediction uses the HPL correction
    ungroup() -> dgemm2
dgemm2 %>% tail(n=10)
dgemm2 %>% str()
#+end_src

#+RESULTS:
#+begin_example

# A tibble: 10 x 11
   func      m     n     k  node  core   cpu type        duration     mnk mnk_id
   <fct> <dbl> <dbl> <dbl> <int> <int> <int> <fct>          <dbl>   <dbl>  <dbl>
 1 dgemm  1306  3172  2011     1     0     2 M2/N2 (pol…   0.605   8.63e9     25
 2 dgemm   259  1215  1047     1     6     2 M2/N2 (pol…   0.0252  6.29e8      1
 3 dgemm   640  1160  9441     1    24     2 M2/N2 (pol…   0.492   7.31e9     21
 4 dgemm   547  3908  3279     1    24     2 M2/N2 (pol…   0.487   7.31e9     21
 5 dgemm  1047  1215   259     1    10     2 M2/N2 (pol…   0.0226  6.29e8      1
 6 dgemm  1841  2133  1615     1    26     2 M2/N2 (pol…   0.469   6.64e9     19
 7 dgemm  1442   912  2781     1    12     2 M2/N2 (pol…   0.253   3.96e9     11
 8 dgemm  3136  9602   321     1     8     2 M2/N2 (pol…   0.629   9.97e9     29
 9 dgemm  4287   416  1304     1    20     2 M2/N2 (pol…   0.160   2.63e9      7
10 dgemm  1475   917  1719     1     8     2 M2/N2 (pol…   0.162   2.63e9      7

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	2290 obs. of  11 variables:
 $ func    : Factor w/ 1 level "dgemm": 1 1 1 1 1 1 1 1 1 1 ...
 $ m       : num  695 7359 1313 1887 547 ...
 $ n       : num  695 311 6716 987 3279 ...
 $ k       : num  695 441 642 1610 3908 ...
 $ node    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ core    : int  18 24 16 4 12 26 30 28 30 12 ...
 $ cpu     : int  2 2 2 2 2 2 2 2 2 2 ...
 $ type    : Factor w/ 4 levels "Reality","M1/N0 (linear)",..: 2 1 1 1 1 1 1 1 1 1 ...
 $ duration: num  0 0.0737 0.3824 0.2065 0.5059 ...
 $ mnk     : num  3.36e+08 1.01e+09 5.66e+09 3.00e+09 7.01e+09 ...
 $ mnk_id  : num  1 3 17 9 21 9 27 7 5 1 ...
#+end_example

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 300 :height 400 :session *R*
MSet1 <- c("#E41A1C", "#000000", "#377EB8", "#FF7F00", 
           "#FFFF33", "#A65628", "#F781BF", "#999999");
plot = ggplot(dgemm2, aes(x=mnk, y=duration,color=type)) + 
    geom_point(alpha=0.3,size=.3) + xlim(0,1.2E10)
    ## geom_point(aes(x=m*n*k+.5E8, y=prediction/1.05),alpha=0.3, color="blue") +
    ## geom_point(aes(x=m*n*k+1E8, y=pred_noise/1.05),alpha=0.3, color="green")
plot = plot + theme_bw() + ylab('Duration (s)') + 
        scale_x_continuous(name = 'M.N.K', breaks = (0:4)*3E9, limits=c(0,1.2E10)) 
plot = plot + annotate('text', x=0, y=0.75, hjust=0, vjust=0, size=2.5, fontface='italic', label='(Both M2 models are shifted to\n the right to improve readability)')
plot = plot + scale_color_manual(values=MSet1, guide=F) + #    scale_color_brewer(palette="Set1")
    theme(legend.position = c(1, 0), legend.justification=c(1, 0), legend.text=element_text(size=8), legend.box.background=element_rect(colour = "black"),
          panel.border=element_rect(colour = "black", fill=NA), legend.title=element_blank()) + #(size = 7, face = "italic")) +
    geom_smooth(data=dgemm2[dgemm2$type=="Reality",], size=.2,
                color="black", method='lm', se=F, fullrange=T) +
    guides(colour = guide_legend(override.aes = list(alpha = 1)))
ggsave(filename="img/prediction/modeling/kernels/dgemm_model_calib.png", plot=plot, width=3.9,height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-Kejzdq/figureKv0dqV.png]]
***** HPL_dlatcpy
Scatter plot to show the time variability and how we model it.

#+begin_src R :results output :session *R2* :exports both
df = read.csv('data/prediction/modeling/kernels/trace_functions.csv')
print(unique(df$func))
# in this experiment, we got the nodes dahu-{1,...,8} and the ranks were mapped in the right order
df$node = 1 + df$rank %/% 32
df$cpu = 2*df$node + df$rank %% 2
df$mnk = df$m * df$n * df$k
df$mn = df$m * df$n
df$mk = df$m * df$k
df$nk = df$n * df$k
head(df)
#+end_src

#+RESULTS:
#+begin_example

[1] dtrsm         dgemm         HPL_dlatcpy   HPL_dlaswp03T HPL_dlaswp02N
Levels: dgemm dtrsm HPL_dlaswp02N HPL_dlaswp03T HPL_dlatcpy

         func     m n  k   start        end    duration rank    mode node cpu
1       dtrsm     2 2 NA 0.01674 0.01678434 0.000044337    0 reality    1   2
2       dgemm 50046 2  2 0.01678 0.01698043 0.000200426    0 reality    1   2
3 HPL_dlatcpy     2 2 NA 0.01726 0.01726033 0.000000326    0 reality    1   2
4       dtrsm     4 4 NA 0.01726 0.01726144 0.000001438    0 reality    1   2
5       dgemm 50044 4  4 0.01727 0.01764994 0.000379944    0 reality    1   2
6       dtrsm     2 2 NA 0.01790 0.01790106 0.000001056    0 reality    1   2
     mnk     mn     mk nk
1     NA      4     NA NA
2 200184 100092 100092  4
3     NA      4     NA NA
4     NA     16     NA NA
5 800704 200176 200176 16
6     NA      4     NA NA
#+end_example

#+begin_src R :results output :session *R2* :exports both
func = df[(df$func == 'HPL_dlatcpy'),]
summary(lm(data=func, duration ~ (I(m*n):factor(cpu))+0))
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = duration ~ (I(m * n):factor(cpu)) + 0, data = func)

Residuals:
       Min         1Q     Median         3Q        Max 
-1.357e-03 -8.570e-06 -7.100e-07  4.000e-08  2.735e-03 

Coefficients:
                        Estimate Std. Error t value Pr(>|t|)    
I(m * n):factor(cpu)2  4.949e-09  1.012e-11 489.036   <2e-16 ***
I(m * n):factor(cpu)3  5.020e-09  9.889e-12 507.660   <2e-16 ***
I(m * n):factor(cpu)4  4.975e-09  1.011e-11 492.166   <2e-16 ***
I(m * n):factor(cpu)5  5.080e-09  1.037e-11 489.933   <2e-16 ***
I(m * n):factor(cpu)6  4.974e-09  1.019e-11 488.265   <2e-16 ***
I(m * n):factor(cpu)7  5.001e-09  1.027e-11 487.150   <2e-16 ***
I(m * n):factor(cpu)8  4.892e-09  1.013e-11 482.801   <2e-16 ***
I(m * n):factor(cpu)9  4.845e-09  1.051e-11 460.972   <2e-16 ***
I(m * n):factor(cpu)10 4.795e-09  1.022e-11 469.275   <2e-16 ***
I(m * n):factor(cpu)11 4.760e-09  1.046e-11 455.167   <2e-16 ***
I(m * n):factor(cpu)13 3.295e-09  3.937e-09   0.837    0.403    
---
codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 9.619e-05 on 21086 degrees of freedom
Multiple R-squared:  0.991,	Adjusted R-squared:  0.991 
F-statistic: 2.116e+05 on 11 and 21086 DF,  p-value: < 2.2e-16
#+end_example

OK. cpu 13, is the one with very few measurements and a weird
behavior. Let's get rid of it.

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R2*
library(ggplot2)
func = df[(df$func == 'HPL_dlatcpy') & (df$cpu!=13),]
func$duration = func$duration*1e3
func$mode_name = factor(ifelse(func$mode=='reality', 'Reality', 'M1/N2 (linear + noise)'))
fake_func = func[1,] # This is just to add a black legend for geom_smooth
fake_func$m = 0
fake_func$n = 0
fake_func$mode_name = factor("M1/N0 (linear)")
fake_func$duration = 0
func = rbind(fake_func, func)
func$mode_name = relevel(func$mode_name, 'Reality')

MSet1 <- c("#E41A1C", "#000000", "#377EB8", "#FF7F00",
           "#FFFF33", "#A65628", "#F781BF", "#999999");
plot = ggplot(func, aes(x=m*n, y=duration, color=mode_name)) +
    geom_smooth(data = func[func$mode == "reality",], aes(group=factor(cpu)), method='lm', 
                se=F, size=.2, color="blue", alpha=.2, fullrange=T) + 
    geom_point(alpha=.5,size=.5) + 
    geom_smooth(data = func[func$mode == "reality",], method='lm', se=F, fullrange=T, linetype=4, color="black")
plot = plot + theme_bw() + ylab('Duration (ms)') + xlab('M.N') +
    xlim(0,max(func$m*func$n)*1.1) +     
    scale_color_brewer(palette="Set1")  +
    scale_color_manual(values=MSet1) +
    theme(legend.position = c(0.3,0.85), legend.title=element_blank()) +
    guides(colour = guide_legend(override.aes = list(alpha = 1))) +
    theme(legend.position = c(1, 0), legend.justification=c(1, 0), legend.text=element_text(size=8), legend.box.background=element_rect(colour = "black"),
          panel.border = element_rect(colour = "black", fill=NA), legend.title=element_blank())

ggsave(filename='img/prediction/modeling/kernels/dlatcpy_model.png', plot=plot, width=3.9,height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-Kejzdq/figureXoNrr1.png]]
*** Network plots                                                :noexport:
**** Downloading the CSV
#+begin_src sh :results output :exports both
mkdir -p data/prediction/modeling/network
cd data/prediction/modeling/network
mkdir -p stampede && cd stampede
wget -c https://gitlab.inria.fr/simgrid/platform-calibration/raw/master/data/stampede_17_06_01-17:14/calibration/testplatform_PingPong.csv -O pingpong.csv
wget -c https://gitlab.inria.fr/simgrid/platform-calibration/raw/master/data/stampede_17_06_01-17:14/calibration/testplatform_Recv.csv -O recv.csv
cd ..
mkdir -p dahu && cd dahu
wget -c https://github.com/Ezibenroc/mpi_calibration/raw/master/dahu/mpi/grenoble_2018-08-29_1808878.zip -O archive.zip
unzip -p archive.zip exp/exp_PingPong.csv > pingpong.csv
unzip -p archive.zip exp/exp_Recv.csv > recv.csv
#+end_src

#+RESULTS:

**** Drawing the regression plots
#+begin_src R :results output :session *R* :exports both
library(ggplot2)
library(dplyr)
library(gridExtra)

read_csv <- function(filename) {
    df = read.csv(filename, header=F)
    colnames(df) = c('func', 'msg_size', 'start', 'duration')
#    df = df[sample(nrow(df), 1000), ]  # take only some points, for quick prototyping of the plot
    return(df)
}

draw_reg <- function(df, calibration_df) {
    platforms = unique(calibration_df$platform)

    # Computing the groups
    df$group = 0
    for(plat in platforms) {
        i = 1
        for(bp in calibration_df[calibration_df$platform == plat,]$breakpoint) {
            df[df$platform==plat & df$msg_size > bp,]$group = i
            i = i+1
        }
    }
    df$group = as.factor(df$group)

    # Basic plot
    plot = ggplot(df, aes(x=msg_size, y=duration, color=group)) + geom_point(size=.5, alpha=0.1)
    plot = plot + scale_x_log10() + scale_y_log10() + theme_bw() + scale_color_discrete(guide=F)
    plot = plot + xlab('Message size (bytes)')  + ylab('Duration (seconds)') # + ylab(paste(unique(df$func), 'duration\n (seconds)'))

    # Computing and plotting the regressions
    df$pred = -1
    for(plat in unique(df$platform)) {
        for(grp in unique(df$group)) {
            for(func in unique(df$func)) {
                index = df$group == grp & df$func == func & df$platform == plat
                reg = lm(duration~msg_size, df[index,])
                df[index,]$pred = predict(reg, df[index,])
            }
        }
    }
    plot = plot + geom_line(aes(y=pred, group=group), data=df, color='black')

    # Plotting the breakpoints
    breakpoints_recv = data.frame(calibration_df)
    breakpoints_recv$func = 'MPI_Recv'
    breakpoints_send = data.frame(calibration_df)
    breakpoints_send$func = 'MPI_Send'
    plot = plot + geom_vline(aes(xintercept=breakpoint), data=rbind(breakpoints_recv, breakpoints_send), linetype='dashed')

    # Plotting the labels
    txt = data.frame(func=rep(unique(df$func), 2), msg_size=rep(c(1), 4), duration=rep(c(5e-5), 4), platform=sort(rep(unique(df$platform), 2)))
    txt$label = paste(toupper(txt$platform), txt$func, sep='\n')
    plot = plot + geom_label(aes(label=label), color='black', data=txt, size=4, hjust=0)

    # Wrapping
    plot = plot + facet_wrap(c('func', 'platform'), nrow=2) + theme(strip.background = element_blank(), strip.text.x = element_blank())
    return(plot)
}

draw_mpi_reg <- function(calibration_df) {
    df = data.frame()
    for(platform in unique(calibration_df$platform)) {
        pingpong_file = paste('data/prediction/modeling/network', platform, 'pingpong.csv', sep='/')
        recv_file     = paste('data/prediction/modeling/network', platform, 'recv.csv',     sep='/')
        df_pingpong = read_csv(pingpong_file)
        df_send = df_pingpong %>% filter(func == 'MPI_Send')
        df_recv = read_csv(recv_file)
        tmp = rbind(df_send, df_recv)
        tmp$platform = platform
        df = rbind(df, tmp)
    }
    return(draw_reg(df, calibration_df))
}
#+end_src

#+RESULTS:

#+NAME: table_mpi_calibration
| platform | breakpoint |
|----------+------------|
| dahu     |       8133 |
| dahu     |      15831 |
| dahu     |      33956 |
| dahu     |      64000 |
| stampede |        150 |
| stampede |       5000 |
| stampede |      17420 |
| stampede |     110000 |

#+begin_src R :results output graphics :var calibrations=table_mpi_calibration :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
plot = draw_mpi_reg(calibrations)
ggsave(filename='img/prediction/emulating/mpi_calibration.png', plot=plot, width=6,height=4, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-Kejzdq/figure8FQI9S.png]]
* Experimental control
** Parameter space
No dataset here, we generate the data.
#+begin_src R :results output :session *R* :exports both
library(dplyr)
library(ggplot2)
library(patchwork)
set.seed(42)

N = 100000
max_prod = 1e10
max_size = 1e4

# First, we generate a dataframe with 'independent' sizes (not truly independent, we reject the
# rows where the product is larger than the limit.
df_inde = data.frame()
while(nrow(df_inde) < N) {
    rem = N-nrow(df_inde)
    tmp = data.frame(m=round(runif(rem, 1, max_size)), n=round(runif(rem, 1, max_size)), k=round(runif(rem, 1, max_size))) %>%
        mutate(prod=m*n*k) %>%
        filter(prod <= max_prod)
    df_inde = rbind(df_inde, tmp)
}
df_inde$mode = "Independent sizes"

# Then, we generate a dataframe with uniform product, again using rejection sampling.
N_unif = N %/% 6 # 6 permutations
df_unif = data.frame()
while(nrow(df_unif) < N_unif) {
    rem = N_unif - nrow(df_unif)
    tmp = data.frame(prod=runif(rem, 1, max_prod)) %>%
        mutate(A=runif(rem, 1, prod**(1/3))) %>%
        mutate(B=runif(rem, 1, (prod/A)**(1/2))) %>%
        mutate(C=prod/A/B) %>%
        filter(A <= max_size, B <= max_size, C <= max_size) %>%
        mutate(A=round(A), B=round(B), C=round(C), prod=A*B*C)
    df_unif = rbind(df_unif, tmp)
}
df_unif = rbind(
    df_unif %>% mutate(m=A, n=B, k=C),
    df_unif %>% mutate(m=A, n=C, k=B),
    df_unif %>% mutate(m=B, n=A, k=C),
    df_unif %>% mutate(m=C, n=A, k=B),
    df_unif %>% mutate(m=B, n=C, k=A),
    df_unif %>% mutate(m=C, n=B, k=A)) %>%
    select(-A, -B, -C) %>%
    mutate(mode="Uniform product")

# Finally we merge the two dataframes
df = rbind(df_unif, df_inde)
str(df)
#+end_src

#+RESULTS:
: 
: 'data.frame':	199996 obs. of  5 variables:
:  $ prod: num  3.28e+09 7.12e+09 6.57e+09 6.81e+07 7.44e+08 ...
:  $ m   : num  1338 1885 228 296 14 ...
:  $ n   : num  1031 843 4520 441 6449 ...
:  $ k   : num  2378 4480 6374 522 8245 ...
:  $ mode: chr  "Uniform product" "Uniform product" "Uniform product" "Uniform product" ...

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 700 :height 300 :session *R*
base_plot = df %>%
    ggplot() +
    geom_histogram(bins=50, position="identity", alpha=0.5, boundary=0) +
    theme_bw() +
    ylab('Count') +
    scale_fill_brewer(palette="Dark2")
p1 = base_plot +
    aes(x=prod, fill=mode) +
    xlab('MNK') +
    theme(legend.background = element_rect(color="black", size=0.1)) +
    theme(legend.position=c(0.7, 0.82), legend.title=element_blank())
p2 = base_plot +
    aes(x=m, fill=mode) +
    xlab('M') +
    scale_y_continuous(position = "right") +
    theme(legend.position="none")
plot = p1 + p2
ggsave(filename='img/experiment/parameter_space/distribution.pdf', plot=plot, width=7, height=3)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-iDrifC/figureEsywBF.png]]

** Randomizing the order
The CSV file used in this section has been dumped by this [[https://github.com/Ezibenroc/calibration_analysis/blob/afc789cbbcc3fdd2cb3c02a8837e2a7fbb0604b2/grvingt/grvingt_proper_randomization.ipynb][notebook]] (cell 2)
using the archives: [[https://github.com/Ezibenroc/calibration_analysis/blob/166ba54222891073608059c3e576b30e7cd0b3ff/grvingt/nancy_2018-07-24_1621460.zip][no randomization]], [[https://github.com/Ezibenroc/calibration_analysis/blob/166ba54222891073608059c3e576b30e7cd0b3ff/grvingt/nancy_2018-07-27_1625117.zip][half randomization]], [[https://github.com/Ezibenroc/calibration_analysis/blob/166ba54222891073608059c3e576b30e7cd0b3ff/grvingt/nancy_2018-08-03_1645238.zip][full randomization]].
*** Plot drawing
#+begin_src R :results output :session *R* :exports both
library(dplyr)
library(ggplot2)
df = read.csv('data/experiment/randomizing_order/mpi_calibration_order.csv')
str(df)
#+end_src

#+RESULTS:
: 
: 'data.frame':	1041500 obs. of  5 variables:
:  $ index   : int  0 1 2 3 4 5 6 7 8 9 ...
:  $ start   : num  0.00316 0.00408 0.00499 0.0059 0.00682 ...
:  $ msg_size: int  765921 765921 765921 765921 765921 765921 765921 765921 765921 765921 ...
:  $ duration: num  7.70e-05 7.32e-05 7.29e-05 7.33e-05 7.28e-05 ...
:  $ shuffled: Factor w/ 3 levels "full","half",..: 3 3 3 3 3 3 3 3 3 3 ...

#+begin_src R :results output :session *R* :exports both
df %>%
    group_by(shuffled) %>%
    summarise(max_size=max(msg_size)) %>%
    as.data.frame() -> tmp
max_size = tmp %>% pull(max_size) %>% min()
str(max_size)
tmp
#+end_src

#+RESULTS:
: 
: `summarise()` ungrouping output (override with `.groups` argument)
: 
:  int 989921
: 
:   shuffled max_size
: 1     full  9981108
: 2     half   989921
: 3     none   989921

We used a larger parameter space in one of the runs. For the plots, we will
restrict every mode to the same size interval.

In fact, we will only plot the half-shuffled and the full-shuffled.

#+begin_src R :results output :session *R* :exports both
print(length(df$msg_size))
df = df %>%
    filter(msg_size <= max_size) %>%
    filter(shuffled %in% c("half", "none")) %>%
    mutate(mode=ifelse(shuffled=="none", "Not shuffled", "Shuffled"))
print(length(df$msg_size))
#+end_src

#+RESULTS:
: [1] 1041500
: 
: [1] 662000

#+begin_src R :results output :session *R* :exports both
plot_mpi = function(df, alpha) {
    return(df %>%
        ggplot() +
        aes(x=msg_size, y=duration) +
        geom_point(alpha=alpha) +
        scale_x_log10() +
        scale_y_log10() +
        theme_bw() +
        labs(x="Message size (bytes)", y="Duration (seconds)") +
        facet_wrap("mode")
    )
}
#+end_src

#+RESULTS:

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
plot = df %>% plot_mpi(alpha=0.1)
ggsave(filename='img/experiment/randomizing_order/raw_data.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-70i53c/figurelb3LJj.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
plot = df %>%
    group_by(msg_size, mode) %>%
    summarize(duration=mean(duration)) %>%
    plot_mpi(alpha=1) + expand_limits(y=c(min(df$duration), max(df$duration)))
ggsave(filename='img/experiment/randomizing_order/aggregated_data.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-70i53c/figure1nJZNB.png]]

Let's take again this aggregated data and build two lists, one of sizes that are
in the lower mode, one of sizes that are in the upper mode.
#+begin_src R :results output :session *R* :exports both
zoom = df %>%
    filter(duration <= 3.5e-6) %>% # removing the 'outliers'
    filter(msg_size >= 100, msg_size <= 1000) %>%
    group_by(msg_size, mode) %>%
    mutate(mean_duration=mean(duration)) %>%
    ungroup()
p = 0.2
bounds = zoom %>%
    filter(mode=="Not shuffled") %>%
    pull(mean_duration) %>%
    quantile(probs=c(p, 1-p))
zoom = zoom %>%
    mutate(category = ifelse(mean_duration <= bounds[[1]], "low", ifelse(mean_duration >= bounds[[2]], "high", "medium")))
selection_size = 3
low_selection = zoom %>%
    filter(category=="low") %>%
    pull(msg_size) %>%
    unique() %>%
    sort() 
high_selection = zoom %>%
    filter(category=="high") %>%
    pull(msg_size) %>%
    unique() %>%
    sort()
low_selection_sample = low_selection  %>% .[. <= 800] %>% tail(n=selection_size)
high_selection_sample = high_selection  %>% .[. <= 800] %>% tail(n=selection_size)
selection = c(low_selection_sample, high_selection_sample)
str(selection)
selection_df = zoom %>%
    mutate(category = ifelse(msg_size %in% low_selection, paste(low_selection_sample, collapse=","), paste(high_selection_sample, collapse=","))) %>%
    mutate(category = paste("{", category, "}", sep="")) %>%
    filter(msg_size %in% selection)
#+end_src

#+RESULTS:
: 
:  int [1:6] 703 767 779 705 741 782

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
library(see) # https://github.com/easystats/see
library(ggbeeswarm)
library(cowplot)
plot = selection_df %>%
    ggplot() +
    aes(x=factor(msg_size), y=duration, color=category) +
    geom_quasirandom(alpha=0.5, dodge.width=1, key_glyph=rectangle_key_glyph(fill=color)) +
    stat_summary(fun="mean", geom="point", color="black", size=4, shape=4) +
    facet_wrap("mode") +
    scale_color_brewer(palette="Dark2") +
    theme_bw() +
    expand_limits(y=0) +
    theme(legend.position="bottom") +
    theme(legend.background = element_rect(color="black", size=0.3)) +
    labs(x="Message size (bytes)", y="Duration (seconds)", color="Message size (bytes)") +
    guides(color=guide_legend(override.aes=list(alpha=1)))
ggsave(filename='img/experiment/randomizing_order/distribution.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-70i53c/figureCRwfze.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
plot = selection_df %>%
    ggplot() +
    aes(x=start, y=duration, color=category) +
    geom_point(alpha=0.5, key_glyph=rectangle_key_glyph(fill=color)) +
    facet_wrap(c("mode", "category"), ncol=4) +
    scale_color_brewer(palette="Dark2") +
    theme_bw() +
    expand_limits(y=0) +
    labs(x="Timestamp (seconds)", y="Duration (seconds)", color="Message size (bytes)") +
    theme(legend.position="bottom") +
    theme(legend.background = element_rect(color="black", size=0.3)) +
    guides(color=guide_legend(override.aes=list(alpha=1)))
ggsave(filename='img/experiment/randomizing_order/evolution.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-70i53c/figureJMCmc9.png]]

Now let's have a quick look at the sizes *before* and *after* the low-duration
calls.
#+begin_src R :results output :session *R* :exports both
df %>%
    filter(mode == 'Not shuffled') %>%
    filter(index %% 10 == 0) %>%
    arrange(index) %>%
    mutate(size_before=lag(msg_size, n=1), size_after=lead(msg_size, n=1)) %>%
    filter(msg_size %in% low_selection) %>%
    group_by(msg_size) %>%
    summarise(duration=mean(duration), size_before=unique(size_before), size_after=unique(size_after)) %>%
    as.data.frame()
#+end_src

#+RESULTS:
#+begin_example

`summarise()` regrouping output by 'msg_size' (override with `.groups` argument)
   msg_size    duration size_before size_after
1       102 1.08950e-06          50        591
2       195 1.29450e-06      667582     254743
3       211 1.16998e-06       16620       9852
4       232 1.21954e-06      495560          3
5       260 1.19262e-06      626942         31
6       279 1.14658e-06        1275          6
7       310 1.18878e-06       12657       6825
8       357 1.20886e-06          30       4640
9       366 1.16614e-06          48       5878
10      383 1.15176e-06          26         29
11      400 1.21260e-06           1       7921
12      411 1.16458e-06         703          3
13      444 1.15260e-06          41          7
14      451 1.18381e-06           3       2930
15      451 1.18381e-06          31     379763
16      476 1.13258e-06          29       8504
17      568 1.14188e-06         779         41
18      601 1.19500e-06        2443     500497
19      646 1.27478e-06      697005      24379
20      679 1.13138e-06        2422         50
21      703 1.12164e-06        1335        411
22      767 1.13044e-06        1054     283616
23      779 1.22874e-06      699352        568
24      960 1.15592e-06        1943       1273
#+end_example

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 700 :height 300 :session *R*
start_exp=14.
duration_exp=0.2
seg_length=2e-7
seg_height=3.8e-6
seg_width=0.1
plot = df %>%
    filter(mode == "Not shuffled", start >= start_exp, start <= start_exp+duration_exp, duration <= 4e-6) %>%
    filter(msg_size <= 1000) %>%
    mutate(category_short = ifelse(duration >= 1.7e-6, "Slow", "Fast")) %>%
    mutate(category = ifelse(category_short=="Slow", "More than 1.7µs", "Less than 1.7µs")) %>% {(
    ggplot(.) +
    aes(x=start, xintercept=start, y=duration, color=category) +
 #   geom_rug(sides="t", position="jitter", alpha=0.5, length=unit(0.1, "npc")) +  # <- very nice, but I needed to not overlap the two colors, so using geom_segment instead
    geom_segment(data=filter(., category_short=="Slow"), size=seg_width, mapping=aes(xend=start, y=seg_height, yend=seg_height+seg_length)) +
    geom_segment(data=filter(., category_short=="Fast"), size=seg_width, mapping=aes(xend=start, y=seg_height+seg_length/2, yend=seg_height-seg_length/2)) +
    geom_point(alpha=0.5, key_glyph=rectangle_key_glyph(fill=color)) +
    scale_color_brewer(palette="Dark2") +
    theme_bw() +
    labs(x="Timestamp (seconds)", y="Duration (seconds)") +
    theme(legend.position="bottom", legend.title=element_blank()) +
    theme(legend.background = element_rect(color="black", size=0.3)) +
    coord_cartesian(ylim = c(9e-7*0, 3.5e-6), clip="off") +
    theme(plot.margin = unit(c(15+5.5,5.5,5.5,5.5), "pt")) +
    guides(color=guide_legend(override.aes=list(alpha=1)))
)}
ggsave(filename='img/experiment/randomizing_order/evolution_rug.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-70i53c/figurewYqaRU.png]]
** Randomizing the sizes
*** Generation method
The CSV files used in this section have been dumpted by this [[https://github.com/Ezibenroc/calibration_analysis/blob/19da3d11a4f559a5742b2e9aba689fdad2909708/dahu/blas/expfile_influence.ipynb][notebook]] (cells 8,
9, 10 and 21) using these [[https://github.com/Ezibenroc/calibration_analysis/tree/19da3d11a4f559a5742b2e9aba689fdad2909708/dahu/blas/expfile_influence/2][archives]] Relevant entry in my journal: 2020-12-01.
**** Temporal evolution of the average performance and the DRAM power consumption
#+begin_src R :results output :session *R* :exports both
library(dplyr)
library(ggplot2)
library(anytime)
library(patchwork)
library(scales)
library(ggrepel)
library(ggbeeswarm)

do_plot = function(frame, y_val, y_label) {
    frame = frame %>%
        mutate(exp_kind=stringr::str_to_title(exp_kind))
    avg = frame %>%
        group_by(exp_kind) %>%
        summarise(val=mean(.data[[y_val]]))
    plot = frame %>%
        ggplot() +
        aes_string(x="exp_kind", y=y_val, fill="exp_kind") +
        ylab(y_label) +
        theme_bw() +
        expand_limits(y=c(min(frame[[y_val]]), max(frame[[y_val]]))) +
        scale_fill_brewer(type='qual', palette='Dark2') +
        scale_color_brewer(type='qual', palette='Dark2') +
        theme(legend.position="none") +
        guides(fill = guide_legend(override.aes = list(alpha=1, shape=21, size=4))) +
        geom_boxplot(outlier.alpha=0, alpha=1) +
        geom_quasirandom(dodge.width=1) +
        xlab('Generation method') +
        ylab(y_label) +
        coord_flip()
    return(plot)
}
#+end_src

#+RESULTS:

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
set.seed(27)
p1 = read.csv("data/experiment/randomizing_sizes/method/dgemm_agr_data.csv") %>%
    filter(node==5, cpu==1) %>%
    do_plot("avg_gflops", "Average performance (Gflop/s)")
p2 = read.csv("data/experiment/randomizing_sizes/method/dgemm_agr_monitoring.csv") %>%
    filter(node==5, cpu==1, kind=="power", subgroup=="dram") %>%
    do_plot("value", "Average DRAM power consumption (W)") +
    theme(axis.text.y = element_blank(), axis.title.y = element_blank())
plot = p1 + p2
ggsave(filename='img/experiment/randomizing_sizes/method/average.pdf', plot=plot, width=7, height=2)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-B5QDBU/figureTmMQZY.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
plot = read.csv("data/experiment/randomizing_sizes/expfile/dgemm_agr_monitoring.csv") %>%
    filter(node==5, cpu==1, kind=="power", subgroup=="dram") %>%
    mutate(start_time=anytime(start_time)) %>%
    mutate(Expfile=ifelse(expfile=="exp_dgemm_a.csv", "A", ifelse(expfile=="exp_dgemm_c.csv", "B", "C"))) %>%
    do_plot("value", "Average DRAM power consumption (W)")
ggsave(filename='img/experiment/randomizing_sizes/expfile/average_power.pdf', plot=plot, width=7, height=3)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-b2kpD9/figureQLe7FU.png]]
*** Expfile
The CSV files used in this section have been dumpted by this [[https://github.com/Ezibenroc/calibration_analysis/blob/ab23ec7e2624a5ca524838a7a9f613252aec0797/dahu/blas/expfile_influence.ipynb][notebook]] (cells 8,
9, 10 and 21) using these [[https://github.com/Ezibenroc/calibration_analysis/tree/dbd0d284a878d4bf4a7e4d86bd6fe590c5f35585/dahu/blas/expfile_influence/1][archives]]. Relevant entry in my journal: 2020-11-25.
**** Temporal evolution of the average performance and the DRAM power consumption
#+begin_src R :results output :session *R* :exports both
library(dplyr)
library(ggplot2)
library(anytime)
library(patchwork)
library(scales)
library(ggrepel)
set.seed(42)

do_plot = function(frame, y_val, y_label) {
    avg = frame %>%
        group_by(Expfile) %>%
        summarise(avg=mean(.data[[y_val]])) %>%
        mutate(start_time=frame %>% pull(start_time) %>% min())
    basic_plot = frame %>%
        ggplot() +
        aes_string(y=y_val, fill="Expfile") +
        ylab(y_label) +
        theme_bw() +
        expand_limits(y=c(min(frame[[y_val]]), max(frame[[y_val]]))) +
        scale_fill_brewer(type='qual', palette='Dark2') +
        scale_color_brewer(type='qual', palette='Dark2') +
        theme(legend.position="none") +
        guides(fill = guide_legend(override.aes = list(alpha=1, shape=21, size=4)))

    p1 = basic_plot +
        geom_boxplot(aes(x=Expfile), outlier.alpha=0, alpha=1) +
        theme(legend.position='none') +
        theme(plot.margin = unit(c(0,0,0,0), "pt"), axis.ticks.length=unit(0, "null")) +
        xlab('Experiment file') +
        ylab(y_label)
    p2 = basic_plot +
        geom_point(shape=21, aes(x=start_time), size=5, alpha=0.7, stroke=0) +
        scale_x_datetime(breaks = date_breaks("1 day")) +
        theme(axis.text.y=element_blank(), axis.ticks.y=element_blank(), axis.title.y=element_blank()) +
        theme(plot.margin = unit(c(0,0,0,0), "pt"), axis.ticks.length=unit(0, "null")) +
        xlab('Timestamp')
    p_label = basic_plot +
        geom_label(data=avg, aes(x=0, y=avg, fill=NA, color=Expfile, label=Expfile)) +
        theme(plot.margin = unit(c(0,0,0,0), "pt"), axis.ticks.length=unit(0, "null")) +
        theme_void() +
        theme(legend.position="none")

    plot = p1 + p_label + p2 + plot_layout(widths=c(5,1,20), guides = 'collect')
    return(plot)
}
#+end_src

#+RESULTS:

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
plot = read.csv("data/experiment/randomizing_sizes/expfile/dgemm_agr_data.csv") %>%
    filter(node==5, cpu==1) %>%
    mutate(start_time=anytime(start_time)) %>%
    mutate(Expfile=ifelse(expfile=="exp_dgemm_a.csv", "A", ifelse(expfile=="exp_dgemm_c.csv", "B", "C"))) %>%
    do_plot("avg_gflops", "Average performance (Gflop/s)")
ggsave(filename='img/experiment/randomizing_sizes/expfile/average_performance.pdf', plot=plot, width=7, height=3)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-b2kpD9/figureI5KhqO.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
plot = read.csv("data/experiment/randomizing_sizes/expfile/dgemm_agr_monitoring.csv") %>%
    filter(node==5, cpu==1, kind=="power", subgroup=="dram") %>%
    mutate(start_time=anytime(start_time)) %>%
    mutate(Expfile=ifelse(expfile=="exp_dgemm_a.csv", "A", ifelse(expfile=="exp_dgemm_c.csv", "B", "C"))) %>%
    do_plot("value", "Average DRAM power consumption (W)")
ggsave(filename='img/experiment/randomizing_sizes/expfile/average_power.pdf', plot=plot, width=7, height=3)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-b2kpD9/figureQLe7FU.png]]
**** Distribution of the regression coefficients
#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
library(dplyr)
library(ggplot2)
library(anytime)
library(patchwork)
library(scales)
library(ggrepel)

plot_bivariate <- function(df, x_col, y_col, color_col) {
    density_plot = ggplot() +
        aes_string(color=color_col, group=color_col) +
        geom_density(data=df) +
        theme_void()

    plot_top = density_plot +
        aes_string(x=x_col)
    plot_right = density_plot +
        aes_string(x=y_col) +
        coord_flip()

    text = df %>%
        group_by_(color_col) %>%
        summarise_all(funs(mean))

    scatter_plot = ggplot(df) +
        aes_string(x=x_col, y=y_col, color=color_col, group=color_col) +
        geom_point() +
        stat_ellipse() +
# Uncomment the following line to put labels on the ellipses
        geom_label(data=text, aes_string(label=color_col), alpha=0.7) +
        theme_minimal() +
        scale_x_continuous(breaks = scales::pretty_breaks(n = 3)) +
        scale_y_continuous(breaks = scales::pretty_breaks(n = 3)) +
        xlab(toupper(x_col)) +
        ylab(toupper(y_col))

    return(
        plot_top + plot_spacer() + scatter_plot + plot_right +
        plot_layout(widths = c(4, 1), heights = c(1, 4)) &
        scale_color_brewer(palette="Dark2", type="qual") &
        theme(legend.position='none')
    )
}

plot = read.csv("data/experiment/randomizing_sizes/expfile/dgemm_agr_data.csv") %>%
    filter(node==5, cpu==1) %>%
    mutate(Expfile=ifelse(expfile=="exp_dgemm_a.csv", "A", ifelse(expfile=="exp_dgemm_c.csv", "B", "C"))) %>%
    mutate(cpu_id=interaction(node, cpu), group=interaction(cpu_id, expfile)) %>%
    plot_bivariate("mnk", "nk", "Expfile")
ggsave(filename='img/experiment/randomizing_sizes/expfile/average_distribution.pdf', plot=plot, width=7, height=5)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-b2kpD9/figurehDHrWR.png]]
**** Individual durations
#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
library(dplyr)
library(ggplot2)

plot = read.csv("data/experiment/randomizing_sizes/expfile/dgemm_raw_data.csv") %>%
    filter(node==5, cpu==1) %>%
    mutate(MNK=as.numeric(m)*as.numeric(n)*as.numeric(k), gflops=2*MNK*1e-9/duration) %>%
    mutate(Expfile=ifelse(expfile=="exp_dgemm_a.csv", "A", ifelse(expfile=="exp_dgemm_c.csv", "B", "C"))) %>%
    ggplot() +
    aes(x=MNK, y=duration, color=Expfile) +
    geom_point(alpha=0.1) +
    facet_wrap("Expfile") +
    scale_color_brewer(palette="Dark2") +
    geom_abline(slope=6.7e-11) +
    theme_bw() +
    ylab("Duration (seconds)") +
    scale_x_continuous(breaks = c(0e9, 4e9, 8e9)) +
    theme(legend.position="none")
ggsave(filename='img/experiment/randomizing_sizes/expfile/raw_data.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-b2kpD9/figurev1kz6K.png]]

** Randomizing the data
The CSV files used in this section have been dumped by the notebooks [[https://github.com/Ezibenroc/presentations/blob/30849c839426038fe6d4840cd4403f0d422136c3/2020/jlesc/fig/notebook_generation_method.ipynb][here]] (using
the archives from this [[https://github.com/Ezibenroc/presentations/tree/30849c839426038fe6d4840cd4403f0d422136c3/2020/jlesc/fig/exp_data/1][directory]]) and [[https://github.com/Ezibenroc/presentations/blob/30849c839426038fe6d4840cd4403f0d422136c3/2020/jlesc/fig/notebook_mask_size.ipynb][here]] (using the archives from this
[[https://github.com/Ezibenroc/presentations/tree/30849c839426038fe6d4840cd4403f0d422136c3/2020/jlesc/fig/exp_data/2][directory]]). You can also see the entries in my journal from 2019/10/25 and
2019/10/29.
*** Generation method
#+begin_src R :results output :session *R* :exports both
library(dplyr)
library(ggplot2)
library(patchwork)

do_plot = function(frame, y_val, y_label, col_val) {
    col_label = gsub("_", " ", col_val)
    col_label = paste(toupper(substr(col_label, 1, 1)), substr(col_label, 2, nchar(col_label)), sep="")
    frame$x_val = ifelse(frame[[col_val]]=="random", "rand",
                  ifelse(frame[[col_val]]=="sequential", "seq", as.character(frame[[col_val]])))
    basic_plot = frame %>%
        ggplot() +
        aes_string(y=y_val, fill=col_val) +
        ylab(y_label) +
        labs(fill=col_label) +
        theme_bw() +
        scale_y_continuous(labels = scales::number_format(accuracy = 0.001)) +
        guides(fill = guide_legend(override.aes = list(alpha=1, shape=21, size=4)))

    p1 = basic_plot +
        geom_boxplot(aes(x=x_val), outlier.alpha=0, alpha=1) +
        theme(legend.position='none') +
#        theme(axis.text.x=element_blank()) +
        xlab(col_label)
    p2 = basic_plot +
        geom_point(shape=21, aes(x=timestamp), size=1, alpha=0.3, stroke=0) +
        theme(axis.text.y=element_blank(), axis.ticks.y=element_blank(), axis.title.y=element_blank()) +
        xlab('Timestamp (s)')

    plot = p1 + p2 + plot_layout(widths=c(1,2), guides = 'collect')
    return(plot)
}
#+end_src

#+RESULTS:

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
read.csv("data/experiment/bit-flips/generation_method_perf.csv") %>%
    do_plot("duration", "Duration (s)", "matrix_content") &
    scale_fill_brewer(type='qual', palette='Dark2') -> plot
ggsave(filename='img/experiment/bit-flips/generation_method_perf.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-bipihK/figureEnXWKR.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
read.csv("data/experiment/bit-flips/generation_method_freq.csv") %>%
    do_plot("frequency", "Frequency (GHz)", "matrix_content") &
    scale_fill_brewer(type='qual', palette='Dark2') -> plot
ggsave(filename='img/experiment/bit-flips/generation_method_freq.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-bipihK/figure5qkT5W.png]]

*** Mask size
#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
read.csv("data/experiment/bit-flips/mask_size_perf.csv") %>%
    mutate(mask_size=factor(mask_size)) %>%
    do_plot("duration", "Duration (s)", "mask_size") &
    scale_fill_brewer(type='seq', palette='Blues') -> plot
ggsave(filename='img/experiment/bit-flips/mask_size_perf.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-bipihK/figureic0oHe.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R*
read.csv("data/experiment/bit-flips/mask_size_freq.csv") %>%
    mutate(mask_size=factor(mask_size)) %>%
    do_plot("frequency", "Frequency (GHz)", "mask_size") &
    scale_fill_brewer(type='seq', palette='Blues') -> plot
ggsave(filename='img/experiment/bit-flips/mask_size_freq.png', plot=plot, width=7, height=3, dpi=200)
plot
#+end_src

#+RESULTS:
[[file:/tmp/babel-bipihK/figureZHGqH0.png]]
